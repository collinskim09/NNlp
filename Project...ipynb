{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BUILDING A MODEL THAT CAN RATE THE SENTIMENT OF A TWEET BASED ON ITS CONTENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction \n",
    "Technology represents the application of knowledge to achieve practical goals in a reproducible manner. In today's rapidly evolving world, over 80 percent of the global population embraces technology as an integral part of their lives. Among the numerous tech giants, Google and Apple stand out as dominant players with an extensive worldwide market presence. These industry leaders have left an indelible mark through their innovative devices, cutting-edge software, and indispensable services. Their influence has been pivotal in fostering connectivity among individuals, effectively transforming our planet into a global village through seamless communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    " In a world where technology has become an integral part of our daily lives, there is an increasing need to understand the sentiments expressed towards tech giants like Google and Apple through social media platforms, particularly Twitter. To address this, the challenge is to develop a robust sentiment analysis model capable of accurately rating the sentiment of tweets based on their content. This model will play a crucial role in assessing public perception and sentiment towards the products and services offered by Google and Apple, allowing businesses and decision-makers to gain valuable insights into customer opinions and preferences in the ever-evolving tech landscape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics of Success:\n",
    " Effectively classification of the tweeter sentiments towards different products.\n",
    "\n",
    "Classification Accuracy: To measure the percentage of correctly classified tweets out of the total tweets in the dataset. A high classification accuracy indicates that the model effectively rates sentiments based on tweet content.\n",
    "\n",
    "Precision and Recall: Precision and recall are essential metrics, especially in sentiment analysis where imbalanced classes are common. Precision measures the accuracy of positive sentiment predictions, while recall measures the ability of the model to identify all positive sentiments correctly. A balance between precision and recall is crucial.\n",
    "\n",
    "F1-Score:It provides a single score that balances the trade-off between precision and recall.\n",
    "\n",
    "Confusion Matrix: Understanding where the model is making mistakes and which sentiment class is more challenging to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research quetions:\n",
    "1. How do brand mentions in tweet text influence the sentiment classification results, particularly for brands like Apple and Google?\n",
    "2. what extent can the sentiment analysis models developed on this dataset be generalized to other similar datasets or social media platforms?\n",
    "3. What are the comparative performances of Logistic Regression and Multinomial Naive Bayes models in classifying sentiment in tweets?\n",
    "4. To what extent can the sentiment analysis models developed on this dataset be generalized to other similar datasets or social media platforms?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives:\n",
    "\n",
    "1. **Continuous Text Preprocessing:** Tokenized tweet text, removed stopwords, eliminated punctuation, and lemmatized words, ensuring that the text data was consistently clean and ready for analysis.\n",
    "\n",
    "2. **Persistent Model Implementation:** implement and compared two sentiment classification models, namely Logistic Regression and Multinomial Naive Bayes,thorough evaluation of model performance.\n",
    "\n",
    "3. **Sustainable Practical Applications:** Evaluated how the insights gained from sentiment analysis could be practically applied in real-world scenarios, such as marketing strategies and customer service enhancements for thebrands and products.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data understanding\n",
    "\n",
    "\n",
    "   - The dataset is sourced from CrowdFlower via data.world.\n",
    "   - It contains over 9,000 tweets that have been rated by human raters for sentiment.\n",
    "   - The sentiment labels are categorized as positive, negative, or neither (neutral).\n",
    "\n",
    "\n",
    "   - The dataset consists of several columns, each serving a specific purpose.\n",
    "   - Key columns in the dataset include:\n",
    "     - `tweet_text`: Contains the text of the tweets.\n",
    "     - `emotion_in_tweet_is_directed_at`: Specifies whether the emotion in the tweet is directed at a brand or product.\n",
    "     - `is_there_an_emotion_directed_at_a_brand_or_product`: Provides sentiment labels (positive, negative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"judge-1377884607_tweet_product_company.csv\", encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9093, 3)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shape of the data\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 9093 rows and 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweet_text                                            object\n",
       "emotion_in_tweet_is_directed_at                       object\n",
       "is_there_an_emotion_directed_at_a_brand_or_product    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the datatypes of different columns\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the three columns are srings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Stopwords: Removing stops words fron the data set\n",
    "\n",
    "Removing Punctuation: Removing punctuation from the remaining words. Punctuation marks, such as periods, commas, and exclamation points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to remove stop words and punctuation from a text column\n",
    "def preprocess_text(text):\n",
    "    if isinstance(text, str):  \n",
    "        words = text.split()\n",
    "    \n",
    "        \n",
    "        # Removing stopwords and punctuation\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        words = [word for word in words if word.lower() not in stop_words]\n",
    "        words = [''.join(c for c in word if c not in string.punctuation) for word in words]\n",
    "        \n",
    "        # Joining the processed words back into a text\n",
    "        return ' '.join(words)\n",
    "    else:\n",
    "        return text \n",
    "\n",
    "columns_to_preprocess = ['tweet_text', 'emotion_in_tweet_is_directed_at']\n",
    "for column in columns_to_preprocess:\n",
    "    data[column] = data[column].apply(preprocess_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During removal of stopwords  didn't remove digits because they are important in making the data make sence for example: cannot drop three in 3g becouse it's defining the network the product is using"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing the tweet_ text and the emotion_in_tweet_is_directed_at columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tokenizing 'tweet_text' column\n",
    "data['tweet_text_tokens'] = data['tweet_text'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else [])\n",
    "\n",
    "# Tokenizing 'emotion_in_tweet_is_directed_at' column\n",
    "data['emotion_tokens'] = data['emotion_in_tweet_is_directed_at'].apply(lambda x: word_tokenize(x) if isinstance(x, str) else [])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>emotion_in_tweet_is_directed_at</th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens</th>\n",
       "      <th>emotion_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wesley83 3G iPhone 3 hrs tweeting RISEAustin d...</td>\n",
       "      <td>iPhone</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[wesley83, 3G, iPhone, 3, hrs, tweeting, RISEA...</td>\n",
       "      <td>[iPhone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jessedee Know fludapp  Awesome iPadiPhone app ...</td>\n",
       "      <td>iPad iPhone App</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[jessedee, Know, fludapp, Awesome, iPadiPhone,...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>swonderlin wait iPad 2 also sale SXSW</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[swonderlin, wait, iPad, 2, also, sale, SXSW]</td>\n",
       "      <td>[iPad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sxsw hope years festival crashy years iPhone a...</td>\n",
       "      <td>iPad iPhone App</td>\n",
       "      <td>Negative emotion</td>\n",
       "      <td>[sxsw, hope, years, festival, crashy, years, i...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sxtxstate great stuff Fri SXSW Marissa Mayer G...</td>\n",
       "      <td>Google</td>\n",
       "      <td>Positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, Fri, SXSW, Marissa, ...</td>\n",
       "      <td>[Google]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          tweet_text  \\\n",
       "0  wesley83 3G iPhone 3 hrs tweeting RISEAustin d...   \n",
       "1  jessedee Know fludapp  Awesome iPadiPhone app ...   \n",
       "2              swonderlin wait iPad 2 also sale SXSW   \n",
       "3  sxsw hope years festival crashy years iPhone a...   \n",
       "4  sxtxstate great stuff Fri SXSW Marissa Mayer G...   \n",
       "\n",
       "  emotion_in_tweet_is_directed_at  \\\n",
       "0                          iPhone   \n",
       "1                 iPad iPhone App   \n",
       "2                            iPad   \n",
       "3                 iPad iPhone App   \n",
       "4                          Google   \n",
       "\n",
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   Negative emotion   \n",
       "1                                   Positive emotion   \n",
       "2                                   Positive emotion   \n",
       "3                                   Negative emotion   \n",
       "4                                   Positive emotion   \n",
       "\n",
       "                                   tweet_text_tokens       emotion_tokens  \n",
       "0  [wesley83, 3G, iPhone, 3, hrs, tweeting, RISEA...             [iPhone]  \n",
       "1  [jessedee, Know, fludapp, Awesome, iPadiPhone,...  [iPad, iPhone, App]  \n",
       "2      [swonderlin, wait, iPad, 2, also, sale, SXSW]               [iPad]  \n",
       "3  [sxsw, hope, years, festival, crashy, years, i...  [iPad, iPhone, App]  \n",
       "4  [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...             [Google]  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping \"tweet_text\",\"emotion_in_tweet_is_directed_at\" columns so as to remain with the tokenized columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=[\"tweet_text\",\"emotion_in_tweet_is_directed_at\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowecase\n",
    "data = data.applymap(lambda x: x.lower() if isinstance(x, str) else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizing the the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Lemmatizing 'tweet_text_tokens' column\n",
    "data['tweet_text_tokens_lemmatized'] = data['tweet_text_tokens'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]\n",
    ")\n",
    "\n",
    "# Lemmatizing 'emotion_tokens' column\n",
    "data['emotion_tokens_lemmatized'] = data['emotion_tokens'].apply(\n",
    "    lambda tokens: [lemmatizer.lemmatize(token) for token in tokens]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens</th>\n",
       "      <th>emotion_tokens</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[wesley83, 3G, iPhone, 3, hrs, tweeting, RISEA...</td>\n",
       "      <td>[iPhone]</td>\n",
       "      <td>[wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...</td>\n",
       "      <td>[iPhone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[jessedee, Know, fludapp, Awesome, iPadiPhone,...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "      <td>[jessedee, Know, fludapp, Awesome, iPadiPhone,...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[swonderlin, wait, iPad, 2, also, sale, SXSW]</td>\n",
       "      <td>[iPad]</td>\n",
       "      <td>[swonderlin, wait, iPad, 2, also, sale, SXSW]</td>\n",
       "      <td>[iPad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[sxsw, hope, years, festival, crashy, years, i...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iPh...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, Fri, SXSW, Marissa, ...</td>\n",
       "      <td>[Google]</td>\n",
       "      <td>[sxtxstate, great, stuff, Fri, SXSW, Marissa, ...</td>\n",
       "      <td>[Google]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   negative emotion   \n",
       "1                                   positive emotion   \n",
       "2                                   positive emotion   \n",
       "3                                   negative emotion   \n",
       "4                                   positive emotion   \n",
       "\n",
       "                                   tweet_text_tokens       emotion_tokens  \\\n",
       "0  [wesley83, 3G, iPhone, 3, hrs, tweeting, RISEA...             [iPhone]   \n",
       "1  [jessedee, Know, fludapp, Awesome, iPadiPhone,...  [iPad, iPhone, App]   \n",
       "2      [swonderlin, wait, iPad, 2, also, sale, SXSW]               [iPad]   \n",
       "3  [sxsw, hope, years, festival, crashy, years, i...  [iPad, iPhone, App]   \n",
       "4  [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...             [Google]   \n",
       "\n",
       "                        tweet_text_tokens_lemmatized emotion_tokens_lemmatized  \n",
       "0  [wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...                  [iPhone]  \n",
       "1  [jessedee, Know, fludapp, Awesome, iPadiPhone,...       [iPad, iPhone, App]  \n",
       "2      [swonderlin, wait, iPad, 2, also, sale, SXSW]                    [iPad]  \n",
       "3  [sxsw, hope, year, festival, crashy, year, iPh...       [iPad, iPhone, App]  \n",
       "4  [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...                  [Google]  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping \"tweet_text_tokens\",\t\"emotion_tokens\" so as to remain with the updated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "data.drop(columns=[\"tweet_text_tokens\",\t\"emotion_tokens\"\t],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...</td>\n",
       "      <td>[iPhone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[jessedee, Know, fludapp, Awesome, iPadiPhone,...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[swonderlin, wait, iPad, 2, also, sale, SXSW]</td>\n",
       "      <td>[iPad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iPh...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, Fri, SXSW, Marissa, ...</td>\n",
       "      <td>[Google]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   negative emotion   \n",
       "1                                   positive emotion   \n",
       "2                                   positive emotion   \n",
       "3                                   negative emotion   \n",
       "4                                   positive emotion   \n",
       "\n",
       "                        tweet_text_tokens_lemmatized emotion_tokens_lemmatized  \n",
       "0  [wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...                  [iPhone]  \n",
       "1  [jessedee, Know, fludapp, Awesome, iPadiPhone,...       [iPad, iPhone, App]  \n",
       "2      [swonderlin, wait, iPad, 2, also, sale, SXSW]                    [iPad]  \n",
       "3  [sxsw, hope, year, festival, crashy, year, iPh...       [iPad, iPhone, App]  \n",
       "4  [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...                  [Google]  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting text data to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to lowercase in the lemmatized columns\n",
    "data['tweet_text_tokens_lemmatized'] = data['tweet_text_tokens_lemmatized'].apply(\n",
    "    lambda tokens: [token.lower() for token in tokens]\n",
    ")\n",
    "\n",
    "data['emotion_tokens_lemmatized'] = data['emotion_tokens_lemmatized'].apply(\n",
    "    lambda tokens: [token.lower() for token in tokens]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...</td>\n",
       "      <td>[iPhone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[jessedee, Know, fludapp, Awesome, iPadiPhone,...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[swonderlin, wait, iPad, 2, also, sale, SXSW]</td>\n",
       "      <td>[iPad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iPh...</td>\n",
       "      <td>[iPad, iPhone, App]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, Fri, SXSW, Marissa, ...</td>\n",
       "      <td>[Google]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                   negative emotion   \n",
       "1                                   positive emotion   \n",
       "2                                   positive emotion   \n",
       "3                                   negative emotion   \n",
       "4                                   positive emotion   \n",
       "\n",
       "                        tweet_text_tokens_lemmatized emotion_tokens_lemmatized  \n",
       "0  [wesley83, 3G, iPhone, 3, hr, tweeting, RISEAu...                  [iPhone]  \n",
       "1  [jessedee, Know, fludapp, Awesome, iPadiPhone,...       [iPad, iPhone, App]  \n",
       "2      [swonderlin, wait, iPad, 2, also, sale, SXSW]                    [iPad]  \n",
       "3  [sxsw, hope, year, festival, crashy, year, iPh...       [iPad, iPhone, App]  \n",
       "4  [sxtxstate, great, stuff, Fri, SXSW, Marissa, ...                  [Google]  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is well tokenized and all text in lower case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will forcus in Binary classification of text.  So I will select the rows with positive ang negative feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting colunms which onlt have positive or negative feedback\n",
    "positive_negative_emotion = data[\n",
    "    (data[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"negative emotion\") |\n",
    "    (data[\"is_there_an_emotion_directed_at_a_brand_or_product\"] == \"positive emotion\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[wesley83, 3g, iphone, 3, hr, tweeting, riseau...</td>\n",
       "      <td>[iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[jessedee, know, fludapp, awesome, ipadiphone,...</td>\n",
       "      <td>[ipad, iphone, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, 2, also, sale, sxsw]</td>\n",
       "      <td>[ipad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iph...</td>\n",
       "      <td>[ipad, iphone, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxsw, starting, ctia, around, corner, googlei...</td>\n",
       "      <td>[android]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[beautifully, smart, simple, idea, rt, madebym...</td>\n",
       "      <td>[ipad, iphone, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[counting, day, sxsw, plus, strong, canadian, ...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[excited, meet, samsungmobileus, sxsw, show, s...</td>\n",
       "      <td>[android]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[find, amp, start, impromptu, parties, sxsw, h...</td>\n",
       "      <td>[android, app]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                    negative emotion   \n",
       "1                                    positive emotion   \n",
       "2                                    positive emotion   \n",
       "3                                    negative emotion   \n",
       "4                                    positive emotion   \n",
       "7                                    positive emotion   \n",
       "8                                    positive emotion   \n",
       "9                                    positive emotion   \n",
       "10                                   positive emotion   \n",
       "11                                   positive emotion   \n",
       "\n",
       "                         tweet_text_tokens_lemmatized  \\\n",
       "0   [wesley83, 3g, iphone, 3, hr, tweeting, riseau...   \n",
       "1   [jessedee, know, fludapp, awesome, ipadiphone,...   \n",
       "2       [swonderlin, wait, ipad, 2, also, sale, sxsw]   \n",
       "3   [sxsw, hope, year, festival, crashy, year, iph...   \n",
       "4   [sxtxstate, great, stuff, fri, sxsw, marissa, ...   \n",
       "7   [sxsw, starting, ctia, around, corner, googlei...   \n",
       "8   [beautifully, smart, simple, idea, rt, madebym...   \n",
       "9   [counting, day, sxsw, plus, strong, canadian, ...   \n",
       "10  [excited, meet, samsungmobileus, sxsw, show, s...   \n",
       "11  [find, amp, start, impromptu, parties, sxsw, h...   \n",
       "\n",
       "   emotion_tokens_lemmatized  \n",
       "0                   [iphone]  \n",
       "1        [ipad, iphone, app]  \n",
       "2                     [ipad]  \n",
       "3        [ipad, iphone, app]  \n",
       "4                   [google]  \n",
       "7                  [android]  \n",
       "8        [ipad, iphone, app]  \n",
       "9                    [apple]  \n",
       "10                 [android]  \n",
       "11            [android, app]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_negative_emotion.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_negative_emotion.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has 3548 rows and 3 columns "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Splitting the data to complete data and the data with missing values and empty list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose is to deal with data separately"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting the complete rows which dont have any missing value or empty list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete rows \n",
    "complete_rows = positive_negative_emotion[positive_negative_emotion['emotion_tokens_lemmatized'].apply(len) > 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data with incomplete rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#incomplete rows\n",
    "missing = positive_negative_emotion[positive_negative_emotion[\"emotion_tokens_lemmatized\"].apply(lambda x: len(x) == 0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[handheld, û÷hoboûª, drafthouse, launch, û÷...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[again, rt, mention, line, apple, store, insan...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[boooo, rt, mention, flipboard, developing, ip...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[know, quotdatavizquot, translates, quotsatani...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[spark, android, teamandroid, award, sxsw, rea...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "46                                    positive emotion   \n",
       "64                                    negative emotion   \n",
       "68                                    negative emotion   \n",
       "103                                   negative emotion   \n",
       "112                                   positive emotion   \n",
       "\n",
       "                          tweet_text_tokens_lemmatized  \\\n",
       "46   [handheld, û÷hoboûª, drafthouse, launch, û÷...   \n",
       "64   [again, rt, mention, line, apple, store, insan...   \n",
       "68   [boooo, rt, mention, flipboard, developing, ip...   \n",
       "103  [know, quotdatavizquot, translates, quotsatani...   \n",
       "112  [spark, android, teamandroid, award, sxsw, rea...   \n",
       "\n",
       "    emotion_tokens_lemmatized  \n",
       "46                         []  \n",
       "64                         []  \n",
       "68                         []  \n",
       "103                        []  \n",
       "112                        []  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling the empty list based on the correspondent tweete text. If it contains words such as 'apple', 'ipad', 'iphone' then there is a high probability the person is addressing it towards apple products and if the tweete text contain 'google', 'android' then  there is a high probability the person is addresssing to a google product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to replace the empty list\n",
    "def replace_empty_lists(row):\n",
    "    if not row['emotion_tokens_lemmatized']:\n",
    "        keywords = row['tweet_text_tokens_lemmatized']\n",
    "        if any(word in keywords for word in ['apple', 'ipad', 'iphone']):\n",
    "            return ['apple']\n",
    "        elif any(word in keywords for word in ['google', 'android']):\n",
    "            return ['google']\n",
    "    return row['emotion_tokens_lemmatized']\n",
    "\n",
    "# Appling the function to replace empty lists\n",
    "missing['emotion_tokens_lemmatized'] = missing.apply(replace_empty_lists, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the empty list which could not be classified weather adressing Google or Apple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the missing items \n",
    "non_missing = missing[missing['emotion_tokens_lemmatized'].apply(lambda x: bool(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[handheld, û÷hoboûª, drafthouse, launch, û÷...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[again, rt, mention, line, apple, store, insan...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[boooo, rt, mention, flipboard, developing, ip...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[know, quotdatavizquot, translates, quotsatani...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[spark, android, teamandroid, award, sxsw, rea...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[smallbiz, need, review, play, google, placesw...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[mention, sxsw, lonelyplanet, austin, guide, i...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[first, day, sxsw, fun, final, presentation, g...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[quotyou, google, canadian, tuxedo, lose, hour...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[shipments, daily, follow, mention, appleatxdt...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "46                                    positive emotion   \n",
       "64                                    negative emotion   \n",
       "68                                    negative emotion   \n",
       "103                                   negative emotion   \n",
       "112                                   positive emotion   \n",
       "131                                   positive emotion   \n",
       "157                                   positive emotion   \n",
       "337                                   positive emotion   \n",
       "386                                   positive emotion   \n",
       "417                                   negative emotion   \n",
       "\n",
       "                          tweet_text_tokens_lemmatized  \\\n",
       "46   [handheld, û÷hoboûª, drafthouse, launch, û÷...   \n",
       "64   [again, rt, mention, line, apple, store, insan...   \n",
       "68   [boooo, rt, mention, flipboard, developing, ip...   \n",
       "103  [know, quotdatavizquot, translates, quotsatani...   \n",
       "112  [spark, android, teamandroid, award, sxsw, rea...   \n",
       "131  [smallbiz, need, review, play, google, placesw...   \n",
       "157  [mention, sxsw, lonelyplanet, austin, guide, i...   \n",
       "337  [first, day, sxsw, fun, final, presentation, g...   \n",
       "386  [quotyou, google, canadian, tuxedo, lose, hour...   \n",
       "417  [shipments, daily, follow, mention, appleatxdt...   \n",
       "\n",
       "    emotion_tokens_lemmatized  \n",
       "46                    [apple]  \n",
       "64                    [apple]  \n",
       "68                    [apple]  \n",
       "103                   [apple]  \n",
       "112                  [google]  \n",
       "131                  [google]  \n",
       "157                   [apple]  \n",
       "337                  [google]  \n",
       "386                  [google]  \n",
       "417                   [apple]  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_missing.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatinating the datasets to have one comprehensive dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatinating the both data frames\n",
    "updated_data = pd.concat([complete_rows, non_missing])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3515, 3)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows that have remained are 3515 indicating we have lost only 33 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
       "      <th>tweet_text_tokens_lemmatized</th>\n",
       "      <th>emotion_tokens_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[wesley83, 3g, iphone, 3, hr, tweeting, riseau...</td>\n",
       "      <td>[iphone]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[jessedee, know, fludapp, awesome, ipadiphone,...</td>\n",
       "      <td>[ipad, iphone, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[swonderlin, wait, ipad, 2, also, sale, sxsw]</td>\n",
       "      <td>[ipad]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[sxsw, hope, year, festival, crashy, year, iph...</td>\n",
       "      <td>[ipad, iphone, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[sxtxstate, great, stuff, fri, sxsw, marissa, ...</td>\n",
       "      <td>[google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9011</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[apparently, line, get, ipad, sxsw, store, gre...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>negative emotion</td>\n",
       "      <td>[hey, anyone, sxsw, signing, group, texting, a...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9049</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[mention, buy, used, ipad, ill, pick, one, tom...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9052</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[mention, could, buy, new, ipad, 2, tmrw, appl...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9054</th>\n",
       "      <td>positive emotion</td>\n",
       "      <td>[guys, ever, plan, attending, sxsw, need, 4, t...</td>\n",
       "      <td>[apple]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3515 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     is_there_an_emotion_directed_at_a_brand_or_product  \\\n",
       "0                                      negative emotion   \n",
       "1                                      positive emotion   \n",
       "2                                      positive emotion   \n",
       "3                                      negative emotion   \n",
       "4                                      positive emotion   \n",
       "...                                                 ...   \n",
       "9011                                   positive emotion   \n",
       "9043                                   negative emotion   \n",
       "9049                                   positive emotion   \n",
       "9052                                   positive emotion   \n",
       "9054                                   positive emotion   \n",
       "\n",
       "                           tweet_text_tokens_lemmatized  \\\n",
       "0     [wesley83, 3g, iphone, 3, hr, tweeting, riseau...   \n",
       "1     [jessedee, know, fludapp, awesome, ipadiphone,...   \n",
       "2         [swonderlin, wait, ipad, 2, also, sale, sxsw]   \n",
       "3     [sxsw, hope, year, festival, crashy, year, iph...   \n",
       "4     [sxtxstate, great, stuff, fri, sxsw, marissa, ...   \n",
       "...                                                 ...   \n",
       "9011  [apparently, line, get, ipad, sxsw, store, gre...   \n",
       "9043  [hey, anyone, sxsw, signing, group, texting, a...   \n",
       "9049  [mention, buy, used, ipad, ill, pick, one, tom...   \n",
       "9052  [mention, could, buy, new, ipad, 2, tmrw, appl...   \n",
       "9054  [guys, ever, plan, attending, sxsw, need, 4, t...   \n",
       "\n",
       "     emotion_tokens_lemmatized  \n",
       "0                     [iphone]  \n",
       "1          [ipad, iphone, app]  \n",
       "2                       [ipad]  \n",
       "3          [ipad, iphone, app]  \n",
       "4                     [google]  \n",
       "...                        ...  \n",
       "9011                   [apple]  \n",
       "9043                   [apple]  \n",
       "9049                   [apple]  \n",
       "9052                   [apple]  \n",
       "9054                   [apple]  \n",
       "\n",
       "[3515 rows x 3 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divinding the data into two: X - The predictor, y - The predict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = updated_data['tweet_text_tokens_lemmatized'].apply(lambda x: ' '.join(x))\n",
    "y = updated_data['is_there_an_emotion_directed_at_a_brand_or_product']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  \n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the logistic curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Logistic Regression Model\n",
    "logistic_regression = LogisticRegression(max_iter=1000)\n",
    "logistic_regression.fit(X_train_tfidf, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = logistic_regression.predict(X_test_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      "[[  7 101]\n",
      " [  2 593]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "negative emotion       0.78      0.06      0.12       108\n",
      "positive emotion       0.85      1.00      0.92       595\n",
      "\n",
      "        accuracy                           0.85       703\n",
      "       macro avg       0.82      0.53      0.52       703\n",
      "    weighted avg       0.84      0.85      0.80       703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate that the model has a relatively high accuracy of 85%. \n",
    "Confusion matrix and the classification report, we observe that the model performs much better in identifying positive emotion than negative emotions. It has relatively low recall for negative emotions, indicating that it struggles to correctly identify negative sentiment.\n",
    "\n",
    "The macro-average and weighted-average metrics provide an overall assessment of model performance, considering both classes. The macro-average F1-score is 0.52, while the weighted-average F1-score is 0.80.\n",
    "\n",
    "The model performs well in identifying positive sentiment, but in detecting negative sentiment it perfors poorly, as indicated by its low recall for negative emotions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ##### modelling using Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initializing and training the Multinomial Naive Bayes model\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n",
      "Confusion Matrix:\n",
      "[[  3 105]\n",
      " [  0 595]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "negative emotion       1.00      0.03      0.05       108\n",
      "positive emotion       0.85      1.00      0.92       595\n",
      "\n",
      "        accuracy                           0.85       703\n",
      "       macro avg       0.93      0.51      0.49       703\n",
      "    weighted avg       0.87      0.85      0.79       703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: The model has an accuracy of 85%, which means it correctly classifies 85% of the tweets into their respective sentiment categories.\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "The model correctly identifies 595 positive sentiment tweets (True Positives).\n",
    "It incorrectly classifies 105 negative sentiment tweets as positive (False Positives).\n",
    "It correctly identifies 3 negative sentiment tweets (True Negatives).\n",
    "There are no False Negatives (negative sentiment tweets incorrectly classified as positive).\n",
    "Classification Report:\n",
    "\n",
    "For the \"negative emotion\" class, the model has perfect precision (1.00) but a very low recall (0.03), resulting in an F1-score of 0.05. This indicates that while the model is precise in identifying negative sentiment, it misses a significant number of negative sentiment tweets.\n",
    "For the \"positive emotion\" class, the model has high precision (0.85), recall (1.00), and F1-score (0.92), indicating that it performs very well in identifying positive sentiment tweets.\n",
    "The weighted-average F1-score is 0.79.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Modelling using svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Initializing and train the Support Vector Machine\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on the test set\n",
    "y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.89\n",
      "Confusion Matrix:\n",
      "[[ 35  73]\n",
      " [  7 588]]\n",
      "Classification Report:\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "negative emotion       0.83      0.32      0.47       108\n",
      "positive emotion       0.89      0.99      0.94       595\n",
      "\n",
      "        accuracy                           0.89       703\n",
      "       macro avg       0.86      0.66      0.70       703\n",
      "    weighted avg       0.88      0.89      0.86       703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print('Confusion Matrix:')\n",
    "print(confusion)\n",
    "print('Classification Report:')\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy: The model has an accuracy of 89%, which means it correctly classifies 89% of the tweets into their respective sentiment categories.\n",
    "\n",
    "Confusion Matrix:\n",
    "\n",
    "The model correctly identifies 588 positive sentiment tweets (True Positives).\n",
    "It incorrectly classifies 73 negative sentiment tweets as positive (False Positives).\n",
    "It correctly identifies 35 negative sentiment tweets (True Negatives).\n",
    "There are 7 False Negatives (negative sentiment tweets incorrectly classified as positive).\n",
    "Classification Report:\n",
    "\n",
    "For the \"negative emotion\" class, the model has moderate precision (0.83) but a relatively low recall (0.32), resulting in an F1-score of 0.47. This indicates that the model is reasonably precise in identifying negative sentiment .\n",
    "For the \"positive emotion\" class, the model performs very well, with high precision (0.89), recall (0.99), and F1-score (0.94), indicating that it excels in identifying positive sentiment tweets.\n",
    "The macro-average F1-score is 0.70, while the weighted-average F1-score is 0.86.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusions:**\n",
    "\n",
    "1. **Logistic Regression Model:**\n",
    "   - Accuracy: 85%\n",
    "   - Performance on Positive Emotion:\n",
    "     - High precision (0.85), recall (1.00), and F1-score (0.92).\n",
    "   - Performance on Negative Emotion:\n",
    "     - Low recall (0.06) and F1-score (0.12).\n",
    "\n",
    "2. **Multinomial Naive Bayes Model:**\n",
    "   - Accuracy: 85%\n",
    "   - Performance on Positive Emotion:\n",
    "     - High precision (0.85), recall (1.00), and F1-score (0.92).\n",
    "   - Performance on Negative Emotion:\n",
    "     - Perfect precision (1.00) but very low recall (0.03) and F1-score (0.05).\n",
    "\n",
    "3. **Support Vector Machine (SVM) Model:**\n",
    "   - Accuracy: 89%\n",
    "   - Performance on Positive Emotion:\n",
    "     - High precision (0.89), recall (0.99), and F1-score (0.94).\n",
    "   - Performance on Negative Emotion:\n",
    "     - Moderate precision (0.83) and recall (0.32), resulting in an F1-score of 0.47.\n",
    "\n",
    "**Recommendations:**\n",
    "\n",
    "1. **Best Model**: Among the three models evaluated, the Support Vector Machine (SVM) model outperforms the others with an accuracy of 89% and good performance in identifying both positive and negative sentiment tweets. Therefore, the SVM model is the recommended choice.\n",
    "\n",
    "\n",
    "2. **Regular Updates**: If this sentiment analysis model is used for real-time monitoring of Twitter sentiment, it should be regularly updated with new data to adapt to changing trends and language usage.\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
